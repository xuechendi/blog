<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[XueChendi]]></title>
  <link href="http://xuechendi.github.io/atom.xml" rel="self"/>
  <link href="http://xuechendi.github.io/"/>
  <updated>2013-12-10T21:59:13+08:00</updated>
  <id>http://xuechendi.github.io/</id>
  <author>
    <name><![CDATA[Chendi.Xue]]></name>
    <email><![CDATA[xuechendi@gmail.com]]></email>
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Heartbeat and DRBD internal]]></title>
    <link href="http://xuechendi.github.io/blog/2013/12/09/heartbeat-and-drbd-internal/"/>
    <updated>2013-12-09T10:20:00+08:00</updated>
    <id>http://xuechendi.github.io/blog/2013/12/09/heartbeat-and-drbd-internal</id>
    <content type="html"><![CDATA[<p>This posting is talking about Heartbeat &amp; DRBD internal</p>

<p>Every high−availability system needs two basic services: to be informed of cluster members joining and leaving the system, and to provide basic communication services for managing a cluster.</p>

<p>Below info is quoted from <a href="http://upcommons.upc.edu/pfc/bitstream/2099.1/4970/1/memoria.pdf" target="_blank">MASTER THESIS of Abraham Iglesias Aparicio</a></p>

<h2>The Linux-HA project: Heartbeat</h2>

<p>Linux-ha project (Linux High Availability project) [5] is an open source suite to build high available clusters. It can run on every known Linux flavor and in some Unices such as FreeBSD and Solaris.
Heartbeat software is the core component of the Linux-HA project and permits building high availability clusters from commodity servers, as it has no hardware dependencies.</p>

<p>The project started in 1998 and is maintained by an open developer’s community. The project is lead by some companies like Novell or IBM. 10 years of development, testing and more than 30.000 production clusters are numbers that would reflect project maturity.</p>

<h3>Heartbeat cluster styles</h3>

<p>There are two different scopes when working with Heartbeat. Two styles of clusters can be configured. Let us say R1 cluster style and R2 cluster style.
R1 cluster style was the first kind of configurations that could be done with Heartbeat. In this configuration there were some limitations such as:</p>

<h5>1. Limitation of nodes in the cluster (it can only accept 2 nodes)</h5>

<h5>2. Cannot perform monitor operations of a cluster resource</h5>

<h5>3. There were almost no options to express dependency information</h5>

<br>


<p>First version of this R2 cluster style was 2.0.0. At the time of writing this document, Heartbeat latest stable version was 2.0.8. Therefore, this version will be the reference of study in this project. R2 is fully compatible with R1 cluster style configuration. It supports up to 16 nodes cluster and an asynchronous logging daemon was added. Moreover, there were some improvements on message architecture.
With R2 cluster style, or next generation of Heartbeat, these limitations were overridden and software architecture changed. Adding more components and functionalities lead to a more complex system but more complete than the R1 cluster style.
Some new components appeared with R2:</p>

<h5>1. ClusterInformationBase</h5>

<h5>2. ClusterResourceManager</h5>

<h5>3. Modular PolicyEngine</h5>

<h5>4. LocalResourceManager</h5>

<h5>5. StonithDaemon</h5>

<br>


<h4>ClusterInformationBase</h4>

<p>ClusterInformationBase (aka CIB) is the component which stores information about the cluster. It is replicated on every node and stores two kind of information:</p>

<h5>1. Static information. It includes definitions of cluster nodes, resources, monitor operations and constraints.</h5>

<h5>2. Dynamic information. CIB stores the current status of the cluster.</h5>

<br>


<p>CIB is formatted in a XML document and must be built following DTD document included with Heartbeat specifications. Cib.xml files can be red in annex 2.1.</p>

<h4>ClusterResourceManager</h4>

<p>The ClusterResourceManager (CRM) component consists on the following components:</p>

<h5>1. ClusterInformationBase</h5>

<h5>2. ClusterResourceManagerDaemon</h5>

<h5>3. PolicyEngine</h5>

<h5>4. Transitioner</h5>

<h5>5. LocalResourceManager</h5>

<br>


<p>The ClusterResourceManagerDaemon (CRMD) runs on every node and coordinates the actions of all other cluster resource managers. It exchanges information with the designated coordinator (DC) and it can be seen as a communication interface between DC and subsystem components such as CIB and LocalResourceManager.</p>

<p>The DC is a special instance of CRMD. It is elected with the help of the list of cluster nodes from the ClusterConsensusManager (CCM) and takes on the responsibilities of ResourceAllocation throughout the cluster. Therefore, DC is the one who delivers CIB information to all slave instances of CRMD.</p>

<p>The PolicyEngine (PE) module is the one who performs computation of the next state in the cluster. It is triggered by any event in the cluster, such as a resource changing state, a node leaving or joining, or CRM event such as a CRM parting or leaving. The PE, takes the input from CIB and runs locally and does not do any network I/O, it only runs an algorithm. It describes the actions and their dependencies necessary to go from the current cluster state to the target cluster state.
When PE returns an action it is passed to the Transitioner. The goal of this component is to make PE’s wishes become true. The new state computed by PE is passed to the Transitioner, which communicates with the LocalResourceManager on every node and informs about the actions decided by PE (start, stop resources).</p>

<h3>ClusterConsensusManager</h3>

<p>The ClusterConsensusManager (CCM) is the one who establishes membership in the cluster. This membership layer is in the middle of Heartbeat, which is the messaging and infrastructure layer, and the new CRM which is the resource allocation layer. CCM information includes new additions to the membership, lost nodes and loss of quorum.</p>

<h3>Stonith daemon</h3>

<p>R2 cluster style features include stonith capabilities. Stonith is an acronym meaning “Shot The Other Node In The Head”.
A stonith daemon is running on every node and receives requests from the CRM’s TE about what and when to reset. An example of when stonith daemon action is used is in a split brain situation. The DC will send a message to the Stonith daemon to reset the sick node. This node will reboot and then will join the cluster again in a healthy way.</p>

<h3>LocalResourceManager</h3>

<p>Finally, the LocalResourceManager (LRM) has the responsibility for performing operations on resources, by using ResourceAgent scripts to carry out the work. ResourceAgent scripts define a set of start, stop or monitor operations, as directed by the CRM, which are used to operate on a resource instance.
LRM also provides information about resources. It can provide a list of resources that are currently primary and its current state.</p>

<h3>Configuration and manageability</h3>

<p>Heartbeat GUI is a user interface to manage Heartbeat clusters. It is delivered in a separate package of Heartbeat core. It is an application developed with python and is able to add, remove nodes or cluster resources.
It is necessary to have connectivity to port 5560/tcp of the cluster node and password for hacluster user running on the cluster nodes.
Heartbeat GUI is executed from a shell and after being authenticated, the main screen of Heartbeat GUI appears. This is how GUI looks like:</p>

<p><img src="http://xuechendi.github.io/images/HA/heartbeat_gui.png" alt="heartbeat_gui" /></p>

<h2>HA overview</h2>

<p><img src="http://xuechendi.github.io/images/HA/pcmk-overview.png" alt="heartbeat_gui" /></p>

<h2>HA(Pacemaker) Internal Components</h2>

<p>Pacemaker itself is composed of four key components (illustrated below in the same color scheme as the previous diagram):</p>

<h5>Heartbeat：将原来的消息通信层独立为heartbeat项目，新的heartbeat只负责维护集群各节点的信息以及它们之前通信；</h5>

<h5>Cluster Glue：相当于一个中间层，它用来将heartbeat和pacemaker关联起来，主要包含2个部分，即为LRM和STONITH。</h5>

<h5>Resource Agent：用来控制服务启停，监控服务状态的脚本集合，这些脚本将被LRM调用从而实现各种资源启动、停止、监控等等。</h5>

<h5>Pacemaker:也就是Cluster Resource Manager （简称CRM），用来管理整个HA的控制中心，客户端通过pacemaker来配置管理监控整个集群。</h5>

<h5>Corosync:a Group Communication System， helps Pacemaker to support popular open source cluster filesystems.</h5>

<pre><code>what is Corosync:
    Corosync包含OpenAIS的核心框架用来对Wilson的标准接口的使用、管理。它为商用的或开源性的集群提供集群执行框架。Corosync执行高可用应用程序的通信组系统，它有以下特征：
    一个封闭的程序组（A closed process group communication model）通信模式，这个模式提供一种虚拟的同步方式来保证能够复制服务器的状态。
    一个简单可用性管理组件（A simple availability manager），这个管理组件可以重新启动应用程序的进程当它失败后。
    一个配置和内存数据的统计（A configuration and statistics in-memory database），内存数据能够被设置，回复，接受通知的更改信息。
    一个定额的系统（A quorum  syste）,定额完成或者丢失时通知应用程序。
</code></pre>

<p><img src="http://xuechendi.github.io/images/HA/pcmk-stack.png" alt="heartbeat_gui" /></p>

<h5>1. CIB (aka. Cluster Information Base)</h5>

<p>The CIB uses XML to represent both the cluster’s configuration and current state of all resources in the cluster. The contents of the CIB are automatically kept in sync across the entire cluster and are used by the PEngine to compute the ideal state of the cluster and how it should be achieved.</p>

<h5>2. CRMd (aka. Cluster Resource Management daemon)</h5>

<p>This list of instructions is then fed to the DC (Designated Co-ordinator). Pacemaker centralizes all cluster decision making by electing one of the CRMd instances to act as a master. Should the elected CRMd process, or the node it is on, fail… a new one is quickly established.</p>

<h5>3. PEngine (aka. PE or Policy Engine)</h5>

<p>The DC carries out the PEngine’s instructions in the required order by passing them to either the LRMd (Local Resource Management daemon) or CRMd peers on other nodes via the cluster messaging infrastructure (which in turn passes them on to their LRMd process).</p>

<p>The peer nodes all report the results of their operations back to the DC and based on the expected and actual results, will either execute any actions that needed to wait for the previous one to complete, or abort processing and ask the PEngine to recalculate the ideal cluster state based on the unexpected results.</p>

<h5>4. STONITHd</h5>

<p>In some cases, it may be necessary to power off nodes in order to protect shared data or complete resource recovery. For this Pacemaker comes with STONITHd. STONITH is an acronym for Shoot-The-Other-Node-In-The-Head and is usually implemented with a remote power switch. In Pacemaker, STONITH devices are modeled as resources (and configured in the CIB) to enable them to be easily monitored for failure, however STONITHd takes care of understanding the STONITH topology such that its clients simply request a node be fenced and it does the rest.</p>

<p><img src="http://xuechendi.github.io/images/HA/pcmk-internals.png" alt="heartbeat_gui" /></p>

<p>A heartbeat is a periodic communication attempt to check for updated policies.</p>

<p>Heartbeat仅仅是个HA软件，它仅能完成心跳监控和资源接管，不会监视它控制的资源或应用程序。要监控资源和应用程序是否运行正常，必须使用第三方的插件，例如ipfail、Mon和Ldirector等。Heartbeat自身包含了几个插件，分别是ipfail、Stonith和Ldirectord，介绍如下。</p>

<p>ipfail的功能直接包含在Heartbeat里面，主要用于检测网络故障，并做出合理的反应。为了实现这个功能，ipfail使用ping节点或者ping节点组来检测网络连接是否出现故障，从而及时做出转移措施。</p>

<p>Stonith插件可以在一个没有响应的节点恢复后，合理接管集群服务资源，防止数据冲突。当一个节点失效后，会从集群中删除。如果不使用Stonith插件，那么失效的节点可能会导致集群服务在多于一个节点运行，从而造成数据冲突甚至是系统崩溃。因此，使用Stonith插件可以保证共享存储环境中的数据完整性。</p>

<p>Ldirector是一个监控集群服务节点运行状态的插件。Ldirector如果监控到集群节点中某个服务出现故障，就屏蔽此节点的对外连接功能，同时将后续请求转移到正常的节点提供服务。这个插件经常用在LVS负载均衡集群中。关于Ldirector插件的使用，将在后续章节详细讲述。</p>

<p>针对系统自身出现问题导致heartbeat无法监控的问题，就需要在Linux内核中启用一个叫watchdog的模块。watchdog是一个Linux内核模块，它通过定时向/dev/watchdog设备文件执行写操作，从而确定系统是否正常运行。如果watchdog认为内核挂起，就会重新启动系统，进而释放节点资源。</p>

<p>在Linux中完成watchdog功能的软件叫softdog。softdog维护一个内部计时器，此计时器在一个进程写入/dev/watchdog设备文件时更新。如果softdog没有看到进程写入/dev/watchdog文件，就认为内核可能出了故障。watchdog超时周期默认是一分钟，可以通过将watchdog集成到Heartbeat中，从而通过Heartbeat来监控系统是否正常运行。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Fusion-io]]></title>
    <link href="http://xuechendi.github.io/blog/2013/12/07/fusion-io/"/>
    <updated>2013-12-07T15:27:00+08:00</updated>
    <id>http://xuechendi.github.io/blog/2013/12/07/fusion-io</id>
    <content type="html"><![CDATA[<p><embed src='http://xuechendi.github.io/slides/fusion-io' allowFullScreen='true' width='100%' height='640' align='middle'></embed>
Powered by <a href="http://lab.hakim.se/reveal-js/#/1" target="_blank">Reveal.js</a></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Graduate design draft]]></title>
    <link href="http://xuechendi.github.io/blog/2013/12/06/Graduate-design-draft/"/>
    <updated>2013-12-06T11:55:00+08:00</updated>
    <id>http://xuechendi.github.io/blog/2013/12/06/Graduate-design-draft</id>
    <content type="html"><![CDATA[<h2>The paper contents:</h2>

<pre><code>1.overview
2.Cache and Consistency(ceph, vertical and horizonal)
3.The atomic transaction(leveldb internal)
4.The design and architecture
5.The implementation
6.The evaluation
7.The wanna do(cache for vm snapshot?)
</code></pre>

<h3>Coherence: Read the right data.</h3>

<h3>Consistency: Write at the right sequence and location, to garantee the right reading data.</h3>

<h2>How to achieve cache consistency?</h2>

<blockquote><p>所有的一致性方案都要求通过某种方式来实现同一CACHE块的<b>串行化</b>访问，不论是通过串行化对通信媒介的访问，还是通过串行化对其他共享结构的访问。</p></blockquote>


<p>Consistency only can be acheived by maintain the sequentialty of accessing devices.</p>

<h2>Vertical data consistency and Horizonal data consistency</h2>

<h3>Vertical data consistency: Require data consistency among memory, persistency cache device(ssd), and also storage backend(ceph cluster).</h3>

<pre><code>1. How ceph cache pool plan to design and architect.
2. System register, memory design.
3. Other Tiering storage.
</code></pre>

<h3>Horizonal data consistency: When the same backend attach to different VM and even different VM on diffent host, how to keep all cache being data consistent and coherent.</h3>

<pre><code>1. Splay? Ceph Metadata subtree updating mechanism?.
2. Multi core system with shared memory design.
3. ???
</code></pre>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[How to do Ceph Latency Breakdown]]></title>
    <link href="http://xuechendi.github.io/blog/2013/12/05/how-to-do-ceph-latency-breakdown/"/>
    <updated>2013-12-05T10:38:00+08:00</updated>
    <id>http://xuechendi.github.io/blog/2013/12/05/how-to-do-ceph-latency-breakdown</id>
    <content type="html"><![CDATA[<h2>The Ceph Latency Breakdown process includes 3 steps:</h2>

<h3>1. Enable Log Configuration or Other performance count mechanism to record the runtime infomation.</h3>

<h3>2. Produce the workload and meanwhile dump the perfcounter</h3>

<h3>3. Parse the perfcounter dump data</h3>

<h2>Details:</h2>

<p>In ceph, a perfcounter mechanism has been adopted to do the latency breakdown, and the runtime info can be dumped by the admin_socket is an internal implementation in Ceph.</p>

<p>example:</p>

<p><1> codes</p>

<figure class='code'><figcaption><span>git diff</span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
</pre></td><td class='code'><pre><code class='c'><span class='line'><span class="n">diff</span> <span class="o">--</span><span class="n">git</span> <span class="n">a</span><span class="o">/</span><span class="n">src</span><span class="o">/</span><span class="n">osd</span><span class="o">/</span><span class="n">OSD</span><span class="p">.</span><span class="n">cc</span> <span class="n">b</span><span class="o">/</span><span class="n">src</span><span class="o">/</span><span class="n">osd</span><span class="o">/</span><span class="n">OSD</span><span class="p">.</span><span class="n">cc</span>
</span><span class='line'><span class="n">index</span> <span class="n">d34bb9c</span><span class="p">.</span><span class="mf">.6</span><span class="n">c308d3</span> <span class="mi">100644</span>
</span><span class='line'><span class="o">---</span> <span class="n">a</span><span class="o">/</span><span class="n">src</span><span class="o">/</span><span class="n">osd</span><span class="o">/</span><span class="n">OSD</span><span class="p">.</span><span class="n">cc</span>
</span><span class='line'><span class="o">+++</span> <span class="n">b</span><span class="o">/</span><span class="n">src</span><span class="o">/</span><span class="n">osd</span><span class="o">/</span><span class="n">OSD</span><span class="p">.</span><span class="n">cc</span>
</span><span class='line'><span class="err">@@</span> <span class="o">-</span><span class="mi">7055</span><span class="p">,</span><span class="mi">10</span> <span class="o">+</span><span class="mi">7055</span><span class="p">,</span><span class="mi">10</span> <span class="err">@@</span> <span class="n">PGRef</span> <span class="n">OSD</span><span class="o">::</span><span class="n">OpWQ</span><span class="o">::</span><span class="n">_dequeue</span><span class="p">()</span>
</span><span class='line'>
</span><span class='line'> <span class="kt">void</span> <span class="n">OSD</span><span class="o">::</span><span class="n">OpWQ</span><span class="o">::</span><span class="n">_process</span><span class="p">(</span><span class="n">PGRef</span> <span class="n">pg</span><span class="p">,</span> <span class="n">ThreadPool</span><span class="o">::</span><span class="n">TPHandle</span> <span class="o">&amp;</span><span class="n">handle</span><span class="p">)</span>
</span><span class='line'> <span class="p">{</span>
</span><span class='line'><span class="o">-</span>  <span class="n">utime_t</span> <span class="n">pg_lock_lat</span> <span class="o">=</span> <span class="n">ceph_clock_now</span><span class="p">(</span><span class="n">g_ceph_context</span><span class="p">);</span>
</span><span class='line'><span class="o">+</span>  <span class="n">utime_t</span> <span class="n">start</span> <span class="o">=</span> <span class="n">ceph_clock_now</span><span class="p">(</span><span class="n">g_ceph_context</span><span class="p">);</span>
</span><span class='line'>   <span class="n">pg</span><span class="o">-&gt;</span><span class="n">lock_suspend_timeout</span><span class="p">(</span><span class="n">handle</span><span class="p">);</span>
</span><span class='line'><span class="o">-</span>  <span class="n">pg_lock_lat</span> <span class="o">=</span> <span class="n">ceph_clock_now</span><span class="p">(</span><span class="n">g_ceph_context</span><span class="p">)</span> <span class="o">-</span> <span class="n">pg_lock_lat</span><span class="p">;</span>
</span><span class='line'><span class="o">-</span>  <span class="n">osd</span><span class="o">-&gt;</span><span class="n">logger</span><span class="o">-&gt;</span><span class="n">tinc</span><span class="p">(</span><span class="n">l_osd_pg_lock_lat</span><span class="p">,</span> <span class="n">pg_lock_lat</span><span class="p">);</span>
</span><span class='line'><span class="o">+</span>  <span class="n">utime_t</span> <span class="n">end</span> <span class="o">=</span> <span class="n">ceph_clock_now</span><span class="p">(</span><span class="n">g_ceph_context</span><span class="p">);</span>
</span><span class='line'><span class="o">+</span>  <span class="n">osd</span><span class="o">-&gt;</span><span class="n">logger</span><span class="o">-&gt;</span><span class="n">tinc</span><span class="p">(</span><span class="n">l_osd_pg_lock_lat</span><span class="p">,</span> <span class="n">end</span> <span class="o">-</span> <span class="n">start</span><span class="p">);</span>
</span><span class='line'>
</span><span class='line'>   <span class="n">OpRequestRef</span> <span class="n">op</span><span class="p">;</span>
</span><span class='line'>   <span class="p">{</span>
</span></code></pre></td></tr></table></div></figure>


<p>Current Ceph Version only enabled admin_socket in Ceph Cluster Side, so we need to enable it in RBD side.</p>

<p><2> dump the data</p>

<figure class='code'><figcaption><span>ceph.conf</span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'><span class="c">#Enable the admin_socket in QEMU RBD</span>
</span><span class='line'>check ceph.conf
</span><span class='line'><span class="nv">perf</span> <span class="o">=</span> <span class="nb">false</span>
</span><span class='line'>-&gt;
</span><span class='line'><span class="c">#perf = false</span>
</span></code></pre></td></tr></table></div></figure>




<figure class='code'><figcaption><span>QEMU disk.xml</span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
</pre></td><td class='code'><pre><code class='xml'><span class='line'><span class="nt">&lt;disk</span> <span class="na">type=</span><span class="s">&#39;network&#39;</span> <span class="na">device=</span><span class="s">&#39;disk&#39;</span><span class="nt">&gt;</span>
</span><span class='line'>  <span class="nt">&lt;driver</span> <span class="na">name=</span><span class="s">&#39;qemu&#39;</span> <span class="na">type=</span><span class="s">&#39;raw&#39;</span> <span class="na">cache=</span><span class="s">&#39;none&#39;</span><span class="nt">/&gt;</span>
</span><span class='line'>  <span class="nt">&lt;source</span> <span class="na">protocol=</span><span class="s">&#39;rbd&#39;</span> <span class="na">name=</span><span class="s">&#39;xcd_8osd/volume-3:admin_socket=/var/run/ceph/node5_1.asok&#39;</span><span class="nt">/&gt;</span>
</span><span class='line'>  <span class="nt">&lt;target</span> <span class="na">dev=</span><span class="s">&#39;vdb&#39;</span> <span class="na">bus=</span><span class="s">&#39;virtio&#39;</span><span class="nt">/&gt;</span>
</span><span class='line'>  <span class="nt">&lt;serial&gt;</span>12f70341-d199-4fca-9270-56e5d6b80061<span class="nt">&lt;/serial&gt;</span>
</span><span class='line'>  <span class="nt">&lt;alias</span> <span class="na">name=</span><span class="s">&#39;virtio-disk1&#39;</span><span class="nt">/&gt;</span>
</span><span class='line'>  <span class="nt">&lt;address</span> <span class="na">type=</span><span class="s">&#39;pci&#39;</span> <span class="na">domain=</span><span class="s">&#39;0x0000&#39;</span> <span class="na">bus=</span><span class="s">&#39;0x00&#39;</span> <span class="na">slot=</span><span class="s">&#39;0x06&#39;</span> <span class="na">function=</span><span class="s">&#39;0x0&#39;</span><span class="nt">/&gt;</span>
</span><span class='line'><span class="nt">&lt;/disk&gt;</span>
</span></code></pre></td></tr></table></div></figure>


<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class='console'><span class='line'><span class="go">virsh attach instance1 disk.xml</span>
</span><span class='line'>
</span><span class='line'><span class="go">ceph --admin-daemon /var/run/ceph/${osd} perf dump &gt;&gt; ${osd}.txt</span>
</span></code></pre></td></tr></table></div></figure>


<hr>


<h2>Below is the summary of all scripts:</h2>

<p><a href ="http://xuechendi.github.io/downloads/Ceph_Latency_Breakdown_Script.zip"><code style="font-family: 'Fjalla One','Georgia','Helvetica Neue',Arial,sans-serif;font-weight:900;font-size:12px;">download the script</code></a></p>

<h3>Script to mkceph:(in the dir &ldquo;mkceph&rdquo;)</h3>

<p>mkceph_with_pg.sh</p>

<h3>Script to produce workload:(all put in the dir &ldquo;run the test&rdquo;)</h3>

<p><b>run.sh</b>: aim to change the <code>ceph.conf</code> op thread number setting, then restart ceph, vm, and call <code>test.sh</code> to start the test. The test result will then be stored in the path &ldquo;/data/xcd/ceph-CephXCD/run_${id}&rdquo;</p>

<p><b>test.sh</b>: aim to clean run a vm_num loadline test, call <code>mhost-volume-test-xcd.sh</code> to run the actual test</p>

<p><b>mhost-volume-test-xcd.sh</b>: calls <code>clean_cache_on_ceph.sh</code>,<code>check_readahead.sh</code>, <code>volume-test_in_vm.sh</code>, <code>all.fio</code>, <code>volume-test_in_pc.sh</code>, <code>ceph_perf_counter_dump.sh</code>, <code>volume-test_in_ceph.sh</code>, <code>check_cephHealth.sh</code> to run the test(producing workload and collecting runtime system info &amp; ceph info), then collects all the data back to the Node1.</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class='console'><span class='line'><span class="gp">#</span>example:
</span><span class='line'><span class="go">./mhost-volume-test-xcd.sh 1 $vm_num 3 4k &quot;vmNum_&quot;$vm_num ${qd} node13_net</span>
</span></code></pre></td></tr></table></div></figure>


<p>tip: There is a VM list stored in file &ldquo;node13_net&rdquo;</p>

<h3>Script to parse the data:</h3>

<p><b>getLatbreakdown.sh</b>: aim to parse latency data from <code>*.asok</code> files using <code>post_perf.py</code></p>

<p><b>getResult.sh</b>: aim to parse iostat, mpstat data. It calls <code>post_volume_xcd.sh</code>, <code>post_osd.sh</code>, <code>post_cpu.sh</code>, <code>iostat.sh</code></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[DRBD and Heartbeat]]></title>
    <link href="http://xuechendi.github.io/blog/2013/12/04/drbd-and-heartbeat/"/>
    <updated>2013-12-04T19:07:00+08:00</updated>
    <id>http://xuechendi.github.io/blog/2013/12/04/drbd-and-heartbeat</id>
    <content type="html"><![CDATA[<p>These days, need to deploy a HA solution in our setup, and just write all these down helping the next time deployment.</p>

<h2>The Overview</h2>

<p><img src="http://xuechendi.github.io/images/HA/IMG_0045.PNG" alt="overview" width=80%></p>

<p>Here we have 2 setups, providing both web service for management and iscsi target service.</p>

<p>What we wanna have is all the LVs in setup1(222.31.76.144) has a mirror in setup2(222.31.76.228) &mdash; so we need DRBD</p>

<p>Then we use LV1 as lun0 to provide iscsi disk to client1, all client1 knows is that his iscsi target provider&rsquo;s ip address is 222.31.76.250(may be setup1 or setup2) &mdash; so we need heartbeat.</p>

<p>Basically, setup1 will response to the client&rsquo;s request, only when setup&rsquo;s eth0 nic doesn&rsquo;t work(this will happen when setup1 is down), setup2 will continue to provide web service and iscsi service.</p>

<p>Ok, another problem, when we need setup2 can continue to provide iscsi service, we need disks in setup to can also be the primary node in drbd semantic, so when data written to setup2, data can be sync to setup1.</p>

<p>Let&rsquo;s just summary all the requirement here:</p>

<ol>
<li><p>Using heartbeat to provide a virtual ip 222.31.76.250 and watch the liveness of both setups.</p></li>
<li><p>Using DRBD to sync LVs in setup1 and setup2, the syncronization can be both sides(dual primary).</p></li>
<li><p>Need to keep in mind, when the sync link(eth0,192.168.1.*) breaks, there will be a split brain situation in our DRBD setting, so we need to record who is the latest iscsi target provider and use that one to recover the DRBD setting.</p></li>
</ol>


<h2>DRBD setting</h2>

<p>1.The installation
we need to install two parts of DRBD, the kmod who is the real implementation of drbd, and the drbdadm, which helps a lot to manage the drbd service.</p>

<figure class='code'><figcaption><span>drbd rpm</span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'>drbd83-8.3.15-2.el5.centos.x86_64.rpm       kmod-drbd83-8.3.15-3.el5.centos.x86_64.rpm
</span></code></pre></td></tr></table></div></figure>


<p>2.The drbd config file
We can start from the drbd conf file /etc/drbd.conf</p>

<figure class='code'><figcaption><span>/etc/drbd.conf</span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'><span class="c">#</span>
</span><span class='line'><span class="c"># please have a a look at the example configuration file in</span>
</span><span class='line'><span class="c"># /usr/share/doc/drbd83/drbd.conf</span>
</span><span class='line'><span class="c">#</span>
</span><span class='line'>include <span class="s2">&quot;drbd.d/global_common.conf&quot;</span>;
</span><span class='line'>include <span class="s2">&quot;drbd.d/*.res&quot;</span>;
</span></code></pre></td></tr></table></div></figure>


<p></p>

<p>As we can see, in this config file,it include a global_common.conf and *.res
The first one writes some common setting for drbd, things like the sync protocol(Async, semi-sync, sync), net rate setting, blah, blah&hellip;
The second one is what we need to build our resource, the config will be like below:</p>

<figure class='code'><figcaption><span>mpx.res</span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'>resource mpx <span class="o">{</span>
</span><span class='line'>    protocol C;
</span><span class='line'>    net <span class="o">{</span>
</span><span class='line'>        allow-two-primaries;
</span><span class='line'>      <span class="o">}</span>
</span><span class='line'>    syncer <span class="o">{</span>
</span><span class='line'>          rate 1024M;  //sync bandwidth
</span><span class='line'>     <span class="o">}</span>
</span><span class='line'>    on super <span class="o">{</span>
</span><span class='line'>        device /dev/drbd0;
</span><span class='line'>        disk /dev/raid0/lv01;
</span><span class='line'>        address 192.168.1.100:7789;
</span><span class='line'>        meta-disk internal;
</span><span class='line'>    <span class="o">}</span>
</span><span class='line'>    on MPXHA <span class="o">{</span>
</span><span class='line'>        device /dev/drbd0;
</span><span class='line'>        disk /dev/vg01/lv01;
</span><span class='line'>        address 192.168.1.152:7789;
</span><span class='line'>        meta-disk internal;
</span><span class='line'>    <span class="o">}</span>
</span><span class='line'><span class="o">}</span>
</span></code></pre></td></tr></table></div></figure>


<p>The protocol part says we will use sync method in this resource
The net part says both nodes can be primary
The last two parts describe the drbd device and the nic they used to sync data(Here we can direclty connect two setup by ethernet line.)</p>

<p>The above *.res should has replication both in setup1 and setup2
After that there is few command we need to first time build this DRBD resource.</p>

<figure class='code'><figcaption><span>first building drbd resource</span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'>drbdadm create-md mpx // this should be <span class="k">done </span>both in setup1 and setup2
</span><span class='line'>service drbd restart // both in setup1 and setup2
</span><span class='line'>
</span><span class='line'>drbdadm primary --force resource // only in setup1
</span><span class='line'>
</span><span class='line'>drbd-overview // can be <span class="k">done </span>both in setup1 or setup2, here I did in setup2
</span><span class='line'>drbd driver loaded OK; device status:
</span><span class='line'>version: 8.3.11 <span class="o">(</span>api:88/proto:86-96<span class="o">)</span>
</span><span class='line'>srcversion: 2D876214BAAD53B31ADC1D6
</span><span class='line'>m:res  cs          ro                 ds
</span><span class='line'>0:mpx  SyncTarget  Secondary/Primary  Inconsistent/UpToDate  C
</span><span class='line'>...    sync<span class="err">&#39;</span>ed:    25.4%              <span class="o">(</span>1373576/1837720<span class="o">)</span>K
</span><span class='line'>
</span><span class='line'>... <span class="nb">wait </span><span class="k">until</span>
</span><span class='line'>
</span><span class='line'>drbd driver loaded OK; device status:
</span><span class='line'>version: 8.3.11 <span class="o">(</span>api:88/proto:86-96<span class="o">)</span>
</span><span class='line'>srcversion: 2D876214BAAD53B31ADC1D6
</span><span class='line'>m:res  cs         ro                 ds                 p  mounted  fstype
</span><span class='line'>0:mpx  Connected  Secondary/Primary  UpToDate/UpToDate  C
</span><span class='line'>
</span><span class='line'>drbdadm primary mpx // in setup2
</span><span class='line'>drbd-overview
</span><span class='line'>drbd driver loaded OK; device status:
</span><span class='line'>version: 8.3.11 <span class="o">(</span>api:88/proto:86-96<span class="o">)</span>
</span><span class='line'>srcversion: 2D876214BAAD53B31ADC1D6
</span><span class='line'>m:res  cs         ro               ds
</span><span class='line'>0:mpx  Connected  Primary/Primary  UpToDate/UpToDate  C
</span></code></pre></td></tr></table></div></figure>


<p>Here is when we use drbd sevice as iscsi lun,yeah, you need this copy both in setup1 and setup2</p>

<figure class='code'><figcaption><span>scst.conf</span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'><span class="c"># Automatically generated by SCST Configurator v2.2.0.</span>
</span><span class='line'>HANDLER vdisk_fileio <span class="o">{</span>
</span><span class='line'>    DEVICE vg01_lv01 <span class="o">{</span>
</span><span class='line'>        filename /dev/drbd0 // ￼ drbd
</span><span class='line'>    <span class="o">}</span>
</span><span class='line'><span class="o">}</span>
</span><span class='line'>TARGET_DRIVER iscsi <span class="o">{</span>
</span><span class='line'>    enabled 1
</span><span class='line'>    TARGET iqn.2011-1212.edu.cuc.storagelab:mpx.target1 <span class="o">{</span>
</span><span class='line'>        cpu_mask 0000ff
</span><span class='line'>        enabled 1
</span><span class='line'>        rel_tgt_id 1
</span><span class='line'>        GROUP xcd <span class="o">{</span>
</span><span class='line'>            LUN 0 vg01_lv01
</span><span class='line'>            INITIATOR iqn.2012-12.cn.edu.cuc.xcd:1234567
</span><span class='line'>            INITIATOR iqn.1991-05.com.microsoft:win-p56rroe0srf
</span><span class='line'>            cpu_mask 0000ff
</span><span class='line'>        <span class="o">}</span>
</span><span class='line'>    <span class="o">}</span>
</span><span class='line'><span class="o">}</span>
</span></code></pre></td></tr></table></div></figure>


<h2>Heartbeat setting</h2>

<ol>
<li>The installation
Seems we can not simply get heartbeat in yum
Here is the solution</li>
</ol>


<figure class='code'><figcaption><span>heartbeat installation</span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
</pre></td><td class='code'><pre><code class='console'><span class='line'><span class="go">Step-1 : Make download folder under the root.</span>
</span><span class='line'><span class="go">[root@setup1 download]# mkdir /download</span>
</span><span class='line'><span class="go">[root@setup1 download]# cd /download/</span>
</span><span class='line'><span class="go">Step-2 : Download EPEL repository.</span>
</span><span class='line'><span class="go">[root@setup1 download]# wget ftp://mirror.switch.ch/pool/1/mirror/scientificlinux/6rolling/i386/os/Packages/epel-release-6-5.noarch.rpm</span>
</span><span class='line'><span class="go">Step-3 : Install Epel RPM.</span>
</span><span class='line'><span class="go">rpm -ivUh epel-release-6-5.noarch.rpm </span>
</span><span class='line'><span class="go">warning: epel-release-6-5.noarch.rpm: Header V4 DSA/SHA1 Signature, key ID 192a7d7d: NOKEY</span>
</span><span class='line'><span class="go">Preparing...                ########################################### [100%]</span>
</span><span class='line'><span class="go">   1:epel-release           ########################################### [100%]</span>
</span><span class='line'><span class="go">Step-4 : Edit epel.repo file ‘/etc/yum.repos.d/epel.repo’ change the line # 6 ‘enable=1 to enable=0′.</span>
</span><span class='line'><span class="go">[root@setup1 download]# vi /etc/yum.repos.d/epel.repo </span>
</span><span class='line'><span class="go">[epel]</span>
</span><span class='line'><span class="go">name=Extra Packages for Enterprise Linux 6 - $basearch</span>
</span><span class='line'><span class="gp">#</span><span class="nv">baseurl</span><span class="o">=</span>http://download.fedoraproject.org/pub/epel/6/<span class="nv">$basearch</span>
</span><span class='line'><span class="gp">mirrorlist=http://mirrors.fedoraproject.org/metalink?repo=epel-6&amp;amp;arch=$</span>basearch
</span><span class='line'><span class="go">failovermethod=priority</span>
</span><span class='line'><span class="go">enabled=0</span>
</span><span class='line'><span class="go">CentOS 6 :  </span>
</span><span class='line'><span class="go">Step-5 : Now we are ready to install Heartbeat with yum command.</span>
</span><span class='line'><span class="go">[root@setup1 download]# yum --enablerepo=epel install heartbeat</span>
</span></code></pre></td></tr></table></div></figure>


<ol>
<li>The setting</li>
</ol>


<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
</pre></td><td class='code'><pre><code class='console'><span class='line'><span class="go">[root@setup1&amp;setup2 download]# cp /usr/share/doc/heartbeat-3.0.4/ha.cf /etc/ha.d/</span>
</span><span class='line'><span class="go">[root@setup1&amp;setup2 download]# cp /usr/share/doc/heartbeat-3.0.4/haresources /etc/ha.d/</span>
</span><span class='line'><span class="go">[root@setup1&amp;setup2 download]# cp /usr/share/doc/heartbeat-3.0.4/authkeys /etc/ha.d/</span>
</span><span class='line'><span class="go">[root@setup1 download]# vim /etc/ha.d/ha.cf</span>
</span><span class='line'><span class="go">debugfile /var/log/ha-debug</span>
</span><span class='line'><span class="go">keepalive 2</span>
</span><span class='line'><span class="go">deadtime 10</span>
</span><span class='line'><span class="go">warntime 6</span>
</span><span class='line'><span class="go">initdead 120</span>
</span><span class='line'><span class="go">udpport 694</span>
</span><span class='line'><span class="go">ucast eth0 222.31.76.228</span>
</span><span class='line'><span class="go">node   super</span>
</span><span class='line'><span class="go">node   MPXHA</span>
</span><span class='line'><span class="go">auto_failback on</span>
</span><span class='line'><span class="go">respawn hacluster /usr/lib64/heartbeat/ipfail</span>
</span><span class='line'><span class="go">[root@setup2 download]# vim /etc/ha.d/ha.cf</span>
</span><span class='line'><span class="go">debugfile /var/log/ha-debug</span>
</span><span class='line'><span class="go">keepalive 2</span>
</span><span class='line'><span class="go">deadtime 10</span>
</span><span class='line'><span class="go">warntime 6</span>
</span><span class='line'><span class="go">initdead 120</span>
</span><span class='line'><span class="go">udpport 694</span>
</span><span class='line'><span class="go">ucast eth0 222.31.76.144</span>
</span><span class='line'><span class="go">node   super</span>
</span><span class='line'><span class="go">node   MPXHA</span>
</span><span class='line'><span class="go">auto_failback on</span>
</span><span class='line'><span class="go">respawn hacluster /usr/lib64/heartbeat/ipfail</span>
</span><span class='line'><span class="go">[root@setup1&amp;setup2 download]# vim /etc/ha.d/haresouces</span>
</span><span class='line'><span class="go">super IPaddr::222.31.76.250/24/eth0</span>
</span><span class='line'><span class="go">[root@setup1&amp;setup2 download]# service heartbeat restart</span>
</span></code></pre></td></tr></table></div></figure>


<h2>There is also one problem we mentioned before called &ldquo;split brain&rdquo;, here is the way to solve this situation</h2>

<p>This situation happens when the eth0(the link used to sync data beween drbd resources are broken), and both drbd will see itself as primary and the other as unknown</p>

<figure class='code'><figcaption><span>when split brain happens</span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
</pre></td><td class='code'><pre><code class='console'><span class='line'><span class="go">[root@super ~]# service drbd status</span>
</span><span class='line'><span class="go">drbd driver loaded OK; device status:</span>
</span><span class='line'><span class="go">version: 8.3.11 (api:88/proto:86-96)</span>
</span><span class='line'><span class="go">srcversion: 2D876214BAAD53B31ADC1D6</span>
</span><span class='line'><span class="go">m:res  cs          ro               ds                 p       mounted  fstype</span>
</span><span class='line'><span class="go">0:mpx  StandAlone  Primary/Unknown  UpToDate/DUnknown  r-----</span>
</span></code></pre></td></tr></table></div></figure>


<p>The way to tackle this problem when both drbd device also act as the iscsi lun</p>

<figure class='code'><figcaption><span>How to solve split brain problem</span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
</pre></td><td class='code'><pre><code class='console'><span class='line'><span class="go">service scst stop</span>
</span><span class='line'><span class="go">drbdadm secondary mpx</span>
</span><span class='line'><span class="go">drbdadm disconnect mpx</span>
</span><span class='line'><span class="go">drbdadm -- --discard-my-data connect mpx</span>
</span><span class='line'><span class="go">ssh 222.31.76.144 &quot;drbdadm connect mpx&quot;</span>
</span><span class='line'>
</span><span class='line'><span class="go">service drbd status </span>
</span><span class='line'>
</span><span class='line'><span class="go">drbd driver loaded OK; device status:</span>
</span><span class='line'><span class="go">version: 8.3.11 (api:88/proto:86-96)</span>
</span><span class='line'><span class="go">srcversion: 2D876214BAAD53B31ADC1D6</span>
</span><span class='line'><span class="go">m:res  cs          ro                 ds</span>
</span><span class='line'><span class="go">0:mpx  SyncTarget  Secondary/Primary  Inconsistent/UpToDate  C</span>
</span><span class='line'><span class="go">...    sync&#39;ed:    25.4%              (1373576/1837720)K</span>
</span><span class='line'>
</span><span class='line'><span class="go">drbd driver loaded OK; device status:</span>
</span><span class='line'><span class="go">version: 8.3.11 (api:88/proto:86-96)</span>
</span><span class='line'><span class="go">srcversion: 2D876214BAAD53B31ADC1D6</span>
</span><span class='line'><span class="go">m:res  cs         ro                 ds                 p  mounted  fstype</span>
</span><span class='line'><span class="go">0:mpx  Connected  Secondary/Primary  UpToDate/UpToDate  C</span>
</span><span class='line'>
</span><span class='line'><span class="go">drbdadm primary mpx</span>
</span><span class='line'>
</span><span class='line'><span class="go">drbd driver loaded OK; device status:</span>
</span><span class='line'><span class="go">version: 8.3.11 (api:88/proto:86-96)</span>
</span><span class='line'><span class="go">srcversion: 2D876214BAAD53B31ADC1D6</span>
</span><span class='line'><span class="go">m:res  cs         ro               ds</span>
</span><span class='line'><span class="go">0:mpx  Connected  Primary/Primary  UpToDate/UpToDate  C</span>
</span><span class='line'>
</span><span class='line'><span class="go">service scst start</span>
</span></code></pre></td></tr></table></div></figure>



]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Just some paitings on Openstack]]></title>
    <link href="http://xuechendi.github.io/blog/2013/11/18/just-some-paitings-on-openstack/"/>
    <updated>2013-11-18T14:27:00+08:00</updated>
    <id>http://xuechendi.github.io/blog/2013/11/18/just-some-paitings-on-openstack</id>
    <content type="html"><![CDATA[<p>Since I got my iPad air, just fell in love with drawing stuffs.</p>

<p>Painted in Nov. 5th afternoon after the discussion of &ldquo;Software Define Storage&rdquo;.</p>

<p><img src="http://xuechendi.github.io/images/Paintings_about_openstack/SDS.PNG" alt="SDS" /></p>

<p>And a draft draw of some Souvenir</p>

<p><img src="http://xuechendi.github.io/images/Paintings_about_openstack/Openstack_souv.PNG" alt="openstack_souv" /></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[System analysis and tools]]></title>
    <link href="http://xuechendi.github.io/blog/2013/11/15/system-analysis-and-tools/"/>
    <updated>2013-11-15T01:09:00+08:00</updated>
    <id>http://xuechendi.github.io/blog/2013/11/15/system-analysis-and-tools</id>
    <content type="html"><![CDATA[<h2>It&rsquo;s really clear of these 2 graphs to remind me all those tools can help to analyse the system</h2>

<h2>So happily sharing here ~~~</h2>

<p><img src="http://xuechendi.github.io/images/system_analysis_tools/overview.jpg" alt="overview" />
<img src="http://xuechendi.github.io/images/system_analysis_tools/tools.jpg" alt="overview" /></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[AIO-STRESS vs. FIO]]></title>
    <link href="http://xuechendi.github.io/blog/2013/11/15/aio-stress-vs-fio/"/>
    <updated>2013-11-15T01:05:00+08:00</updated>
    <id>http://xuechendi.github.io/blog/2013/11/15/aio-stress-vs-fio</id>
    <content type="html"><![CDATA[<p>There is no big gap to me in producing workload by AIO-STREE and FIO.</p>

<p>Just because I haven&rsquo;t using much more advanced feature in FIO like replay trace, and I just using libaio as the driver.</p>

<p>But here, I just wanna show some interesting test to see some behavior by different setting of io_depth and io_batch. And <code>sadly</code> that is just some wrong setting I did before and produced some strange data then I just realized how these settings mean. T_T</p>

<h2>Just follow my lead to see how I found this wrong setting. ^_^</h2>

<p><img src="http://xuechendi.github.io/images/AIO_vs_FIO/1.png" alt="findings" /></p>

<p>After a loadline test of io_depth setting, I just found the figures followed some rules, so using qemu logs, I draw above graph. This is a graph recording the io request intervals sending from qemu to librbd, and catched in librbd logs.</p>

<p>As we can see, when we set the queue_depth as 8, the first io request has quite small interval(0.075ms), but the interval between the 8th and 9th io request is pretty long(1.6ms). And if we set the queue_depth as 16, or 32. The burst interval happened just between the 16th to 17th, and 32th to 33th respectively.</p>

<p>So there comes the deduction:
Queue will send out all requests, then wait the last request completes . After that it starts to send out new queue.</p>

<h2>How to prove it?</h2>

<h3>Methodology:</h3>

<ol>
<li>. Set queue depth = 64</li>
<li>. make the 42th request sleep 3s in completion thread</li>
</ol>


<h3>&mdash;> If RBD waits 3s then receives the 65th requests, we can confirm the deduction.</h3>

<h3>How to do this?</h3>

<p>There is a function in librbd named C_AioRead::finish in AioCompletion.cc, so what we need to do is just randomly block this function for 3s, and see what happens.</p>

<p><img src="http://xuechendi.github.io/images/AIO_vs_FIO/2.png" alt="proving" /></p>

<p>Aha! The results just show as what we expect.</p>

<h3>But there are still 3 possibilities can produce result like this.</h3>

<p>1.Wrong workload setting?
2.Ceph RBD design ?  if there is some lock in finish thread that blocks the submit thread
3.Virtio ?</p>

<p>The situation produced by FIO</p>

<p><img src="http://xuechendi.github.io/images/AIO_vs_FIO/3.png" alt="proving" /></p>

<p>From this graph, we can see the result is really different by using aio-stress, which can help us to exclude last two possibilities. That means we must do some wrong setting in aio-stress or aio-stress just have some wierd strategy design.</p>

<p>Also we can see the difference in logs.</p>

<p><img src="http://xuechendi.github.io/images/AIO_vs_FIO/4.png" alt="proving" /></p>

<p><code>Here I will add some aio-stress codes digging into soon, just not now~ Sorry</code></p>

<hr>


<p>The right setting for random io in aio-stress to act more meet our demand (Here I said random io is because this setting may result in no io merge in sequential io)</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='console'><span class='line'><span class="go">./aio-stress -O -o 3 -i 1 -d 64 -r4k -s 4m /dev/vdb</span>
</span></code></pre></td></tr></table></div></figure>


<p><img src="http://xuechendi.github.io/images/AIO_vs_FIO/5.png" alt="proving" /></p>

<p><img src="http://xuechendi.github.io/images/AIO_vs_FIO/6.png" alt="proving" /></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[How to break into Ceph Codes]]></title>
    <link href="http://xuechendi.github.io/blog/2013/11/15/how-to-break-into-ceph-codes/"/>
    <updated>2013-11-15T01:00:00+08:00</updated>
    <id>http://xuechendi.github.io/blog/2013/11/15/how-to-break-into-ceph-codes</id>
    <content type="html"><![CDATA[<p>Working in Progress, will be finished by this weekend</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[ObjectCacher: RBD Cache Codes]]></title>
    <link href="http://xuechendi.github.io/blog/2013/11/15/objectcacher-rbd-cache-codes/"/>
    <updated>2013-11-15T00:58:00+08:00</updated>
    <id>http://xuechendi.github.io/blog/2013/11/15/objectcacher-rbd-cache-codes</id>
    <content type="html"><![CDATA[<p>There is some cache mechanism in Ceph RBD.
And it is now in memory cache which supports write through and write back.</p>

<p>In this post, I would post what I have learnt from ObjectCacher codes.</p>

<h2>How to deploy RBD Cache</h2>

<p>there is a really clear instruction in ceph.com, just linked here <code><a href="http://ceph.com/docs/master/rbd/rbd-config-ref/?highlight=rbd%20cache">Ceph RBD Cache setting</a></code></p>

<h2>How to record log from RBD</h2>

<p>There is a little tricky to record log in RBD sides, because if you simply add the log settings in ceph.conf, you can only get logs when you do something using &ldquo;rbd&rdquo; command, (I just cannot remember what is the exact command, will add this later ), etc. So simply adding log settings in ceph.conf(client side) can not help you to get logs from QEMU to librbd, the reason is unknown to me, but I just find a way to walk around this.</p>

<p>All you need to do is to add log setting in you instance.xml, then using libvirt to boot this instance or also you can just attach a new disk by using xml like below.</p>

<figure class='code'><figcaption><span>disk.xml</span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
</pre></td><td class='code'><pre><code class='xml'><span class='line'><span class="nt">&lt;disk</span> <span class="na">type=</span><span class="s">&#39;network&#39;</span> <span class="na">device=</span><span class="s">&#39;disk&#39;</span><span class="nt">&gt;</span>
</span><span class='line'>  <span class="nt">&lt;driver</span> <span class="na">name=</span><span class="s">&#39;qemu&#39;</span> <span class="na">type=</span><span class="s">&#39;raw&#39;</span> <span class="na">cache=</span><span class="s">&#39;none&#39;</span><span class="nt">/&gt;</span>
</span><span class='line'>  <span class="nt">&lt;source</span> <span class="na">protocol=</span><span class="s">&#39;rbd&#39;</span> <span class="na">name=</span><span class="s">&#39;xcd_8osd/volume-3:debug_rbd=20:debug_objectcacher=20:log_file=/tmp/qemu-rbd.log&#39;</span><span class="nt">/&gt;</span>
</span><span class='line'>  <span class="nt">&lt;target</span> <span class="na">dev=</span><span class="s">&#39;vdb&#39;</span> <span class="na">bus=</span><span class="s">&#39;virtio&#39;</span><span class="nt">/&gt;</span>
</span><span class='line'>  <span class="nt">&lt;serial&gt;</span>12f70341-d199-4fca-9270-56e5d6b80061<span class="nt">&lt;/serial&gt;</span>
</span><span class='line'>  <span class="nt">&lt;alias</span> <span class="na">name=</span><span class="s">&#39;virtio-disk1&#39;</span><span class="nt">/&gt;</span>
</span><span class='line'>  <span class="nt">&lt;address</span> <span class="na">type=</span><span class="s">&#39;pci&#39;</span> <span class="na">domain=</span><span class="s">&#39;0x0000&#39;</span> <span class="na">bus=</span><span class="s">&#39;0x00&#39;</span> <span class="na">slot=</span><span class="s">&#39;0x06&#39;</span> <span class="na">function=</span><span class="s">&#39;0x0&#39;</span><span class="nt">/&gt;</span>
</span><span class='line'><span class="nt">&lt;/disk&gt;</span>
</span></code></pre></td></tr></table></div></figure>


<p></p>

<p>After attach this disk, you can find logs in /tmp/qemu-rbd.log or you can just write to qemu log.</p>

<figure class='code'><figcaption><span>write log to</span><a href='http://xuechendi.github.io/var/libvirt/qemu/xxxxx(instance_name).log'>link</a></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='xml'><span class='line'>  <span class="nt">&lt;source</span> <span class="na">protocol=</span><span class="s">&#39;rbd&#39;</span> <span class="na">name=</span><span class="s">&#39;xcd_8osd/volume-3:debug_rbd=20:debug_objectcacher=20:log_to_stderr=true&#39;</span><span class="nt">/&gt;</span>
</span></code></pre></td></tr></table></div></figure>


<p>There is a really clear codes path we can find from logs, so just using log to debug or hack into the rbd codes.</p>

<h2>Dig into the codes</h2>

<p>If we enable rbd cache in ceph.conf(client side), the ObjectCacher object is created when this rbd image attach to the vm.
Here is the overview.</p>

<p><img src="http://xuechendi.github.io/images/RBD_Cache/overview.png" width=60%></p>

<p>From above we can see each RBD has a object to store all information name ImageCtx(image context), so there is only one ObjectCacher in one RBD cache and also different RBD images can not share their cache till now.</p>

<p>ObjectCacher uses poolid, oid(objectid), then offset and length to index cache in memory.</p>

<p>Then here is a graph to show how ceph using ObjectCacher.</p>

<p><img src="http://xuechendi.github.io/images/RBD_Cache/workflow_send_req.png" width=100%></p>

<p><img src="http://xuechendi.github.io/images/RBD_Cache/workflow_recv_req.png" width=50%></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Study of Data distribution methods--Crush]]></title>
    <link href="http://xuechendi.github.io/blog/2013/11/15/crush-ceph-object-distribution-method/"/>
    <updated>2013-11-15T00:51:00+08:00</updated>
    <id>http://xuechendi.github.io/blog/2013/11/15/crush-ceph-object-distribution-method</id>
    <content type="html"><![CDATA[<p>wanna learn, mark here</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Device-Mapper deep dive]]></title>
    <link href="http://xuechendi.github.io/blog/2013/11/14/device-mapper-deep-dive/"/>
    <updated>2013-11-14T19:40:00+08:00</updated>
    <id>http://xuechendi.github.io/blog/2013/11/14/device-mapper-deep-dive</id>
    <content type="html"><![CDATA[<p>I used to stuck in all these terms and concepts for like really long time, just trying to get everything clear by writing.</p>

<h2>Storage subsystem</h2>

<h3>Overview</h3>

<p><img src="http://xuechendi.github.io/images/dm_deep_dive/overview.png" alt="overview" width=80%></p>

<p>BIO is the unit to map data in the memory to generic block offset.
When generic block layer gets bio units, it calls io scheduler to combine bios into request to specific device.
Then requests can be sent to real device or virtual block device like software raid or logic volume(using MD or Device Mapper modules).</p>

<p><img src="http://xuechendi.github.io/images/dm_deep_dive/bio.png" alt="bio" width=80%></p>

<p>Actually BIO units point to a much smaller unit named bio_vec which is the exactly unit point to the memory, and BIO also has one field record which block device and which sector it wanna to read/write.(Notice, the block device here is kind of a generic idea, could be some virtual block device)</p>

<p>The smart use of bio_vec help kernel to support scatter/Gather I/O, so that BIO can map some scatter part in mem to some continuous part in block device.</p>

<p><img src="http://xuechendi.github.io/images/dm_deep_dive/request.png" alt="request" width=80%></p>

<p>When BIO unit received by generic block layer, kernel will do some &ldquo;merge and sort&rdquo; operations then hand the combined BIOs to block device. All these work can be done in the IO scheduler layer and then all BIO units are combined into one and one request, which also be linked by a pointer named &ldquo;request_queue&rdquo; store in bdev struct(gendisk).</p>

<p>Then the whole idea is pretty clear, there is a picture shows some important function to translate a fs syscall into requests to block devices.</p>

<p><img src="http://xuechendi.github.io/images/dm_deep_dive/functions.png" alt="functions" width=50%></p>

<p>Submit_bio is a generic api to submit bio to generic block layer(of course by its name&hellip;)</p>

<p>generic_make_request puts BIO into bio_list, then __generic_make_request will see if this bio is suitable to make request or it is delivered to some stack device like Device Mapper(in this situation, __generic_make_request will produce a new bio and call generic_make_request).</p>

<p>__make_request_fn() then pus BIO into request_queue, if this function returns 0, the BIO is delivered to the real block device, or it may continues to call __make_request_fn until it delivered to real block device(like Device Mapper).</p>

<p>In fact, the request_queue also will not be directly tackled by block device, the device will use some method named &ldquo;Plugging/Unplugging&rdquo; to tackles these requests.</p>

<p><img src="http://xuechendi.github.io/images/dm_deep_dive/structures.png" alt="structures" width=50%></p>

<p>Now let&rsquo;s see a linked graph of some important structs in block-level subsystem. Every block device has a field named gendisk(generic disk), and generic disk has a field to record its request_queue, and since each type of block device has its own implementation of read and write, the gendisk also has a field named private_data to point to the corresponding block device(also, the block device can be real or virtual).</p>

<h2>Then, after all the general idea of block-layer subsystem, let&rsquo;s talk about <code>Device Mapper</code></h2>

<h3>What is Device-Mapper</h3>

<ul>
<li>A block device mapping facility available in Linux Kernel.</li>
<li>A component required by LVM2 to support the mapping between logical volumes and physical storage devices.</li>
<li>Device-mapper provides a generic way to create virtual layers of block devices that can do different things on top of real block devices like striping, concatenation, mirroring, snapshotting, etc&hellip;</li>
</ul>


<h3>Here is the Usecase</h3>

<p>Before lv creation</p>

<p><img src="http://xuechendi.github.io/images/dm_deep_dive/Before lv creation.png" alt="Before lv creation" width=40%></p>

<p>After lv creation</p>

<p><img src="http://xuechendi.github.io/images/dm_deep_dive/after lv creation.png" alt="after lv creation" width=40%></p>

<p>The thing should notice here is that a dm-0 device in /sys/block is created, which indicates that Logic Volume is a &ldquo;device mapper&rdquo; device.</p>

<p><img src="http://xuechendi.github.io/images/dm_deep_dive/after lv creation2.png" alt="after lv creation" width=40%></p>

<h3>another device mapper usecase</h3>

<p><img src="http://xuechendi.github.io/images/dm_deep_dive/dm_usecase2.png" alt="dm_usecase2" width=60%></p>

<h3>Here is the Device Mapper Overview</h3>

<p><img src="http://xuechendi.github.io/images/dm_deep_dive/dm_overview.png" alt="dm_overview" width=50%></p>

<p><img src="http://xuechendi.github.io/images/dm_deep_dive/dm_struct.png" alt="dm_struct" width=50%></p>

<p>DM Devices in Ubuntu 12.10,kernel 3.6.3</p>

<p><img src="http://xuechendi.github.io/images/dm_deep_dive/dm_targets.png" alt="dm_targets" width=50%></p>

<p>Linear Device target-type example</p>

<figure class='code'><figcaption><span>linear-device-struct</span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
</pre></td><td class='code'><pre><code class='c'><span class='line'><span class="k">static</span> <span class="k">struct</span> <span class="n">target_type</span> <span class="n">linear_target</span> <span class="o">=</span> <span class="p">{</span><span class="err">   </span>
</span><span class='line'>  <span class="p">.</span><span class="n">name</span><span class="err">   </span><span class="o">=</span> <span class="s">&quot;linear&quot;</span><span class="p">,</span><span class="err">   </span>
</span><span class='line'>  <span class="p">.</span><span class="n">version</span> <span class="o">=</span> <span class="p">{</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">},</span><span class="err">   </span>
</span><span class='line'>  <span class="p">.</span><span class="n">module</span> <span class="o">=</span> <span class="n">THIS_MODULE</span><span class="p">,</span><span class="err">   </span>
</span><span class='line'>  <span class="p">.</span><span class="n">ctr</span><span class="err">    </span><span class="o">=</span> <span class="n">linear_ctr</span><span class="p">,</span><span class="err">   </span>
</span><span class='line'>  <span class="p">.</span><span class="n">dtr</span><span class="err">    </span><span class="o">=</span> <span class="n">linear_dtr</span><span class="p">,</span><span class="err">   </span>
</span><span class='line'>  <span class="p">.</span><span class="n">map</span><span class="err">    </span><span class="o">=</span> <span class="n">linear_map</span><span class="p">,</span><span class="err">   </span>
</span><span class='line'>  <span class="p">.</span><span class="n">status</span> <span class="o">=</span> <span class="n">linear_status</span><span class="p">,</span><span class="err">   </span>
</span><span class='line'>  <span class="p">.</span><span class="n">ioctl</span><span class="err">  </span><span class="o">=</span> <span class="n">linear_ioctl</span><span class="p">,</span><span class="err">   </span>
</span><span class='line'>  <span class="p">.</span><span class="n">merge</span><span class="err">  </span><span class="o">=</span> <span class="n">linear_merge</span><span class="p">,</span><span class="err">   </span>
</span><span class='line'>  <span class="p">.</span><span class="n">iterate_devices</span> <span class="o">=</span> <span class="n">linear_iterate_devices</span><span class="p">,</span>
</span><span class='line'><span class="p">}</span>
</span></code></pre></td></tr></table></div></figure>


<h3>Let&rsquo;s see the codes</h3>

<figure class='code'><figcaption><span>How DM handle the device creation command?</span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
</pre></td><td class='code'><pre><code class='c'><span class='line'><span class="kt">int</span> <span class="nf">dm_create</span><span class="p">(</span><span class="kt">int</span> <span class="n">minor</span><span class="p">,</span> <span class="k">struct</span> <span class="n">mapped_device</span> <span class="o">**</span><span class="n">result</span><span class="p">){</span>
</span><span class='line'><span class="err">   </span>   <span class="k">struct</span> <span class="n">mapped_device</span> <span class="o">*</span><span class="n">md</span><span class="p">;</span>
</span><span class='line'>      <span class="n">md</span> <span class="o">=</span> <span class="n">alloc_dev</span><span class="p">(</span><span class="n">minor</span><span class="p">);</span><span class="err">   </span> 
</span><span class='line'>  <span class="k">if</span> <span class="p">(</span><span class="o">!</span><span class="n">md</span><span class="p">)</span><span class="err">       </span>      
</span><span class='line'>      <span class="k">return</span> <span class="o">-</span><span class="n">ENXIO</span><span class="p">;</span><span class="err"> </span>   
</span><span class='line'>  <span class="n">dm_sysfs_init</span><span class="p">(</span><span class="n">md</span><span class="p">);</span><span class="err">   </span>   
</span><span class='line'>  <span class="o">*</span><span class="n">result</span> <span class="o">=</span> <span class="n">md</span><span class="p">;</span><span class="err">   </span> 
</span><span class='line'>  <span class="k">return</span> <span class="mi">0</span><span class="p">;</span>
</span><span class='line'><span class="p">}</span>
</span></code></pre></td></tr></table></div></figure>




<figure class='code'><figcaption><span>How DM handle the read/write command? </span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
</pre></td><td class='code'><pre><code class='c'><span class='line'><span class="k">static</span> <span class="kt">void</span> <span class="nf">dm_request</span><span class="p">(</span><span class="k">struct</span> <span class="n">request_queue</span> <span class="o">*</span><span class="n">q</span><span class="p">,</span> <span class="k">struct</span> <span class="n">bio</span> <span class="o">*</span><span class="n">bio</span><span class="p">)</span>
</span><span class='line'><span class="p">{</span>
</span><span class='line'>  <span class="k">struct</span> <span class="n">mapped_device</span> <span class="o">*</span><span class="n">md</span> <span class="o">=</span> <span class="n">q</span><span class="o">-&gt;</span><span class="n">queuedata</span><span class="p">;</span>
</span><span class='line'>
</span><span class='line'>  <span class="k">if</span> <span class="p">(</span><span class="n">dm_request_based</span><span class="p">(</span><span class="n">md</span><span class="p">))</span>
</span><span class='line'>      <span class="n">blk_queue_bio</span><span class="p">(</span><span class="n">q</span><span class="p">,</span> <span class="n">bio</span><span class="p">);</span>  <span class="c1">//Using dm_target rules to reconstruct the bio</span>
</span><span class='line'>  <span class="k">else</span>
</span><span class='line'>      <span class="n">_dm_request</span><span class="p">(</span><span class="n">q</span><span class="p">,</span> <span class="n">bio</span><span class="p">);</span>    <span class="c1">//split and process this bio</span>
</span><span class='line'><span class="p">}</span>
</span></code></pre></td></tr></table></div></figure>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[resume]]></title>
    <link href="http://xuechendi.github.io/blog/2013/11/14/resume/"/>
    <updated>2013-11-14T14:08:00+08:00</updated>
    <id>http://xuechendi.github.io/blog/2013/11/14/resume</id>
    <content type="html"><![CDATA[<h1>Xue Chendi (薛晨笛)
<a href ="http://xuechendi.github.io/downloads/Resume_XueChendi.pdf"><code style="font-family: 'Fjalla One','Georgia','Helvetica Neue',Arial,sans-serif;font-weight:900;font-size:12px;">download the resume</code></a>
</h1>


<h3>0086-18600035546; xuechendi@gmail.com</h3>


<br>


<hr>


<h2>SKILLS</h2>


<ul>
    <li>Linux kernel/module programming experience</li>
    <li>PHP-based website development experience</li>
    <li>Familiar with block-level storage subsystem (iSCSI and Device-Mapper) </li>
    <li>Linux system operating maintenance experience</li>
    <li>CET-6(556)、IELTS(6.5)</li>
</ul>


<br>


<hr>


<h2>EDUCATION</h2>


<div style="width:100%;">
    <div style="width:20%;">2011.9 - Present</div>
    <div style="width:80%;padding-left:5%;">
        <ul>
            <li>Communication University of China</li>
            <li>Masters of Computer software and theory</li>
            <li>Concentration in Distributed storage, ranking 1st at first year&#8217;s courses learning</li>
        </ul>
    </div>
    <div style="width:20%;">2007.9 - 2011.7</div>
    <div style="width:80%;padding-left:5%;">
        <ul>
            <li>Communication University of China</li>
            <li>Major in computer science and technology with GPA of 3.61.</li>
            <li>Minor in Digital Art, college of Animation.</li>
        </ul>
    </div>
</div>


<br>


<hr>


<h2>PROJECT EXPERIENCE</h2>


<div style="width:100%;">
    <div style="width:20%;">2011.7 - Present</div>
    <div style="width:80%;padding-left:5%;">
        <ul>
            <li>Low energy-consuming storage devices development and industrialization</li>
            <li>National science and technology support program(2011BAH04B05)</li>
            <li>Develop a storage management system based on B/S architecture to integrate main Linux storage APIs and also do some optimization to help system administrators to setup raid, LV,iSCSI devices, FC devices, NFS, and CIFS, also manage basic service operations.</li>
        </ul>
    </div>
    <div style="width:20%;">2010.1 - 2011.6</div>
    <div style="width:80%;padding-left:5%;">
        <ul>
            <li>Research of semantic storage system for MP3</li>
            <li>National undergraduate innovation project</li>
            <li>Develop a system that stores MP3 files and metadata separately, then uses metadata/tags to build a RDF triples that can do semantic search of files. In order to optimise the search speed, the system also uses the fast-page mechanism.</li>
        </ul>
    </div>
</div>


<br>


<hr>


<h2>ACADEMIC ACHEIVEMENT</h2>


<div style="width:100%;">
    <div style="width:20%;">2013</div>
    <div style="width:80%;padding-left:5%;">
        <ul>
            <li>《The Optimization of network link aggregation for iSCSI》</li>
            <li>As the first and primary author</li>
            <li>Accepted by The 19th National Conference of Information Storage 2013</li>
        </ul>
    </div>
    <div style="width:20%;">2011</div>
    <div style="width:80%;padding-left:5%;">
        <ul>
            <li>《Research of semantic storage system for MP3》</li>
            <li>As the first and primary author</li>
            <li>IEEE Digital Object Identifier: 10.1109/CECNET.2011.5768656</li>
        </ul>
    </div>
</div>


<br>


<hr>


<h2>INTERNSHIP</h2>


<div style="width:100%;">
    <div style="width:20%;">2013</div>
    <div style="width:80%;padding-left:5%;">
        <ul>
            <li>INTEL R&D CENTER , SSG/SOTC</li>
            <li>Daily work mainly concentrate on CEPH testing and tuning</li>
            <li>Community contribution mainly focus on Openstack-cinder</li>
        </ul>
    </div>
</div>


<br>


<hr>


<h2>SCHOOL ACTIVITY</h2>


<div style="width:100%;">
    <div style="width:20%;">2008</div>
    <div style="width:80%;padding-left:5%;">
        <li>Leader of Part-time Job Service Propaganda Department</li>
    </div>
</div>


<br>


<hr>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[aboutme]]></title>
    <link href="http://xuechendi.github.io/blog/2013/11/14/aboutme/"/>
    <updated>2013-11-14T11:01:00+08:00</updated>
    <id>http://xuechendi.github.io/blog/2013/11/14/aboutme</id>
    <content type="html"><![CDATA[<p>Hi, This is Chendi.Xue, a girl from China and have huge interest in Storage.
I am building this website to share stuff I am into.
Please feel free to contact me in any reason ~</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[First post to Octopress]]></title>
    <link href="http://xuechendi.github.io/blog/2013/11/13/first-post-to-octopress/"/>
    <updated>2013-11-13T00:34:00+08:00</updated>
    <id>http://xuechendi.github.io/blog/2013/11/13/first-post-to-octopress</id>
    <content type="html"><![CDATA[<h1>This is XueChendi</h1>

]]></content>
  </entry>
  
</feed>
